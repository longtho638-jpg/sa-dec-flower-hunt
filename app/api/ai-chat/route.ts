import { GoogleGenerativeAI } from "@google/generative-ai";
import { NextResponse, NextRequest } from "next/server";
import { supabase } from "@/lib/supabase";

// Initialize Gemini
const apiKey = process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY;

const genAI = apiKey ? new GoogleGenerativeAI(apiKey) : null;
const model = genAI ? genAI.getGenerativeModel({ model: "gemini-1.5-flash" }) : null;

const SYSTEM_INSTRUCTION = `
B·∫°n l√† Dr. Flower üë®‚Äç‚öïÔ∏èüå∏, m·ªôt chuy√™n gia v·ªÅ hoa ƒë·∫øn t·ª´ L√†ng hoa Sa ƒê√©c, ƒê·ªìng Th√°p.
Phong c√°ch c·ªßa b·∫°n:
- Th√¢n thi·ªán, nhi·ªát t√¨nh, ƒë·∫≠m ch·∫•t mi·ªÅn T√¢y Nam B·ªô ("Nghen", "ƒê√≥ nha", "C∆∞ng x·ªâu").
- S·ª≠ d·ª•ng nhi·ªÅu emoji li√™n quan ƒë·∫øn hoa v√† thi√™n nhi√™n.
- Ki·∫øn th·ª©c s√¢u r·ªông v·ªÅ c√°c lo·∫°i hoa T·∫øt (C√∫c M√¢m X√¥i, Hoa Gi·∫•y, C√°t T∆∞·ªùng...).
- Lu√¥n t∆∞ v·∫•n d·ª±a tr√™n: Phong th·ªßy, M·ªánh gia ch·ªß, Kh√¥ng gian nh√†, v√† Ng√¢n s√°ch.
- M·ª•c ti√™u: Khuy·∫øn kh√≠ch kh√°ch h√†ng mua hoa ho·∫∑c ƒë·∫øn Sa ƒê√©c check-in.

Khi t∆∞ v·∫•n:
1. Khen ng·ª£i kh√°ch h√†ng n·∫øu h·ªç c√≥ gu t·ªët.
2. G·ª£i √Ω c·ª• th·ªÉ (VD: "M·ªánh kim th√¨ n√™n ch∆∞ng tr·∫≠u C√∫c M√¢m X√¥i v√†ng r·ª±c r·ª° nghen!").
3. Nh·∫Øc nh·ªü v·ªÅ c√°ch chƒÉm s√≥c ƒë·ªÉ hoa t∆∞∆°i l√¢u.
`;

export async function POST(req: NextRequest) {
    if (!apiKey || !model) {
        return NextResponse.json(
            { error: "Missing API Key. Please add GEMINI_API_KEY to .env.local" },
            { status: 500 }
        );
    }

    try {
        // Security Check: Verify Auth Token
        const authHeader = req.headers.get('Authorization');
        const token = authHeader?.split(' ')[1];

        if (!token) {
            return NextResponse.json({ error: 'Unauthorized: Missing Token' }, { status: 401 });
        }

        const { data: { user }, error: authError } = await supabase.auth.getUser(token);
        if (authError || !user) {
            return NextResponse.json({ error: 'Unauthorized: Invalid Token' }, { status: 401 });
        }

        const { message, context, history } = await req.json();

        // Construct chat with history if needed, for now simplistic single turn with context
        const prompt = `
${SYSTEM_INSTRUCTION}

Ng·ªØ c·∫£nh hi·ªán t·∫°i: ${context ? JSON.stringify(context) : 'Kh√¥ng c√≥'}
L·ªãch s·ª≠ chat: ${JSON.stringify(history || [])}

Kh√°ch h·ªèi: "${message}"

Dr. Flower tr·∫£ l·ªùi:
`;

        const result = await model.generateContent(prompt);
        const response = await result.response;
        const text = response.text();

        return NextResponse.json({ reply: text });
    } catch (error) {
        console.error("Gemini API Error:", error);
        return NextResponse.json(
            { error: "Dr. Flower ƒëang b·∫≠n chƒÉm hoa, th·ª≠ l·∫°i x√≠u nghen!" },
            { status: 500 }
        );
    }
}
